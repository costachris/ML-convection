{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import and preprocess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is some amount of rain 61.0% of the time\n",
      "There is a rate of >3 mm/day 20.2% of the time\n",
      "There is convection 65.5% of the time\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from sklearn.ensemble.forest import RandomForestRegressor, RandomForestClassifier\n",
    "import os\n",
    "from sklearn import preprocessing, metrics\n",
    "from importlib import reload\n",
    "import sknn.mlp\n",
    "from sklearn import tree  #for graphing random forest tree\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "inline_rc = dict(mpl.rcParams)\n",
    "import src.nnload as nnload\n",
    "import src.nntrain as nntrain\n",
    "import src.nnnetcdf as nnnetcdf\n",
    "import src.nnplot as nnplot\n",
    "\n",
    "# Set script parameters\n",
    "minlev = 0.0\n",
    "rainonly = False\n",
    "evaluate_classifiers = False\n",
    "evaluate_regressors = False\n",
    "write_nn_to_netcdf = False\n",
    "fig_dir = '/Users/jgdwyer/mitbox/scripts/nn/figs/'\n",
    "data_dir = '/Users/jgdwyer/mitbox/scripts/nn/data/'\n",
    "\n",
    "# Load data\n",
    "x, y, Pout, lat, lev, dlev, timestep = nnload.loaddata(data_dir + 'nntest.nc', minlev)\n",
    "\n",
    "# Ensure that input and outputs are lined up in time!\n",
    "x=x[1:,:]\n",
    "y=y[0:-1,:]\n",
    "\n",
    "# Print some statistics about rain and limit to when it's raining if True\n",
    "x, y, Pout = nnload.limitrain(x, y, Pout, rainonly)\n",
    "    \n",
    "# Store when convection occurs\n",
    "cv = nnload.whenconvection(y)\n",
    "        \n",
    "# Normalize input using the scikit-learn preprocessing tools\n",
    "# Constrain inputs and outputs between 0 and 1\n",
    "# Since outputs are sparse, don't shift the mean\n",
    "scaler_x = preprocessing.MinMaxScaler(feature_range=(-1.0,1.0))\n",
    "scaler_y = preprocessing.MaxAbsScaler()\n",
    "\n",
    "# Randomly choose samples\n",
    "samples = np.random.choice(x.shape[0], x.shape[0], replace=False)\n",
    "x1,x2,x3    = nnload.pp(x,  samples, scaler_x)\n",
    "y1,y2,y3    = nnload.pp(y,  samples, scaler_y)\n",
    "cv1,cv2,cv3 = nnload.pp(cv, samples, None, scale_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, train, evaluate, and store regressors NN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_600R_mom0.9reg0.0001\n"
     ]
    }
   ],
   "source": [
    "# Build, train, and save model\n",
    "from importlib import reload\n",
    "reload(nntrain)\n",
    "n_iter = 10000\n",
    "batch_size = 100\n",
    "r_mlp, r_str                  = nntrain.build_nn('regress',['Rectifier'],[600],batch_size,'momentum',\n",
    "                                                 n_stable=100, regularize = 'L2', weight_decay = 0.0001)\n",
    "print(r_str)\n",
    "r_mlp, r_errors, r_besterrors = nntrain.train_nn(r_mlp,r_str,x1,y1,x2,y2)\n",
    "pickle.dump([r_mlp, r_str, r_errors, r_besterrors],  open(data_dir + 'regressors/' + r_str + '.pkl', 'wb'))\n",
    "\n",
    "# Save model in netcdf format if requested\n",
    "if write_nn_to_netcdf:\n",
    "    nnnetcdf.write_netcdf_twolayer(r_mlp, 'regress', datadir + 'netcdf_models/' + r_str + '_neural_weights_regressor.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all NNs to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize regressors\n",
    "trained_regressors = ['r_15R_mom0.9','r_16R_mom0.9','r_17R_mom0.9','r_800R_mom0.9','r_800R_mom0.9reg0.0001']\n",
    "N_r = len(trained_regressors)\n",
    "r_mlp = [0]*N_r\n",
    "r_str = [0]*N_r\n",
    "r_errors=np.empty((n_iter,N_r))\n",
    "r_besterrors=np.empty((n_iter,N_r))\n",
    "r_errors[:]=np.NAN\n",
    "r_besterrors[:]=np.NAN\n",
    "\n",
    "# Load regressors\n",
    "for i,r in enumerate(trained_regressors):\n",
    "    r_mlp[i], r_str[i], err, berr = pickle.load(open(data_dir + 'regressors/' + r + '.pkl', 'rb'))\n",
    "    r_errors[:len(err),i]      =  err\n",
    "    r_besterrors[:len(berr),i] = berr\n",
    "# Compare them and plot output\n",
    "nntrain.plot_regressors_scores(r_mlp,r_str,x2,y2,fig_dir + 'compare/','r')\n",
    "nntrain.plot_model_error_over_time(r_errors, r_besterrors, r_str, fig_dir + 'compare/','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot test data evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the model we want to do a detailed evaulation for\n",
    "r_str_eval = 'r_800R_mom0.9reg0.0001'\n",
    "r_mlp_eval, _, _, _ = pickle.load(open(data_dir + 'regressors/' + r_str_eval + '.pkl', 'rb'))\n",
    "\n",
    "# Set figure path and create directory if it does not exist\n",
    "figpath = fig_dir + r_str_eval + '/'\n",
    "if not os.path.exists(figpath):\n",
    "    os.makedirs(figpath)\n",
    "    \n",
    "# Set the true and predicted test data\n",
    "y3_true = y2\n",
    "y3_pred = r_mlp_eval.predict(x2)\n",
    "\n",
    "# Plot means and standard deviations\n",
    "nnplot.plot_means_stds(y3_true, y3_pred, lev, figpath)\n",
    "\n",
    "# Plot correlation coefficient, explained variance, and rmse\n",
    "nnplot.plot_error_stats(y3_true, y3_pred, lev, figpath)\n",
    "\n",
    "# Plot a time series of precipitaiton\n",
    "nnplot.plot_precip(y3_true, y3_pred, dlev, figpath)\n",
    "\n",
    "# Plot the enthalpy conservation\n",
    "nnplot.plot_enthalpy(y3_true, y3_pred, dlev, figpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     r_mlp.append(build_nn('regress',['Rectifier','Rectifier']            ,[500,500]    ,n_iter,batch_size,'momentum'))\n",
    "#     r_mlp.append(build_nn('regress',['Rectifier','Rectifier','Rectifier'],[200,200,200],n_iter,batch_size,'momentum'))\n",
    "#     r_mlp.append(build_nn('regress',['Tanh','Tanh','Tanh']               ,[100,100,100],n_iter,batch_size,'momentum'))\n",
    "#     r_mlp.append(build_nn('regress',['Tanh','Tanh']                      ,[500,500]    ,n_iter,batch_size,'momentum'))\n",
    "#     r_mlp.append(build_nn('regress',['Tanh','Tanh']                      ,[200,200]    ,n_iter,batch_size,'momentum'))\n",
    "#     r_mlp.append(build_nn('regress',['Tanh']                             ,[500]        ,n_iter,batch_size,'momentum'))\n",
    "#     r_mlp.append(build_nn('regress',['Tanh','Tanh']                      ,[500,500]    ,n_iter,batch_size,'momentum',learning_momentum=0.7))\n",
    "#     r_mlp.append(build_nn('regress',['Tanh','Tanh']                      ,[500,500]    ,n_iter,batch_size,'sgd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "r_str_eval = 'r_800R_mom0.9reg0.0001'\n",
    "r_mlp_eval, _, _, _ = pickle.load(open(data_dir + 'regressors/' + r_str_eval + '.pkl', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Regressor(batch_size=100,\n",
       "     callback={'on_epoch_finish': <function store_stats at 0x114136048>},\n",
       "     debug=False, dropout_rate=None, f_stable=0.001,\n",
       "     hidden0=<sknn.nn.Layer `Rectifier`: name='hidden0', units=800, frozen=False>,\n",
       "     layers=[<sknn.nn.Layer `Rectifier`: name='hidden0', units=800, frozen=False>, <sknn.nn.Layer `Linear`: name='output', units=60, frozen=False>],\n",
       "     learning_momentum=0.9, learning_rate=0.01, learning_rule='momentum',\n",
       "     loss_type=None, n_iter=10000, n_stable=10000, normalize=None,\n",
       "     output=<sknn.nn.Layer `Linear`: name='output', units=60, frozen=False>,\n",
       "     parameters=None, random_state=None, regularize='L2', valid_set=None,\n",
       "     valid_size=0.0, verbose=None, warning=None, weight_decay=0.0001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_mlp_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
