{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that I am extracting the parameters correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_test = r_mlp.predict(x3)\n",
    "out_test = scaler_y.inverse_transform(out_test)\n",
    "w1 = r_mlp.get_parameters()[0].weights\n",
    "w2 = r_mlp.get_parameters()[1].weights\n",
    "w3 = r_mlp.get_parameters()[2].weights\n",
    "b1 = r_mlp.get_parameters()[0].biases\n",
    "b2 = r_mlp.get_parameters()[1].biases\n",
    "b3 = r_mlp.get_parameters()[2].biases\n",
    "\n",
    "xscale_min = scaler_x.data_min_\n",
    "xscale_max = scaler_x.data_max_\n",
    "yscale_absmax = scaler_y.max_abs_\n",
    "\n",
    "out_test_check = np.dot(x3,w1) + b1\n",
    "out_test_check[out_test_check<0] = 0\n",
    "out_test_check = np.dot(out_test_check,w2) + b2\n",
    "out_test_check[out_test_check<0] = 0\n",
    "out_test_check = np.dot(out_test_check,w3) + b3\n",
    "\n",
    "out_test_check = out_test_check*yscale_absmax\n",
    "ptl.plot(out_test-out_test_check)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that I understand what classification is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_w1=c_mlp.get_parameters()[0].weights\n",
    "c_w2=c_mlp.get_parameters()[1].weights\n",
    "c_w3=c_mlp.get_parameters()[2].weights\n",
    "c_b1=c_mlp.get_parameters()[0].biases\n",
    "c_b2=c_mlp.get_parameters()[1].biases\n",
    "c_b3=c_mlp.get_parameters()[2].biases\n",
    "\n",
    "out_test_check = np.dot(x1            ,c_w1) + c_b1\n",
    "out_test_check[out_test_check<0] = 0\n",
    "out_test_check = np.dot(out_test_check,c_w2) + c_b2\n",
    "out_test_check[out_test_check<0] = 0\n",
    "out_test_check = np.dot(out_test_check,c_w3) + c_b3\n",
    "\n",
    "expo =  np.exp(out_test_check)\n",
    "expos = np.sum(expo,axis=1)\n",
    "\n",
    "#foo=np.empty((x1.shape[0], 2))\n",
    "foo[:,0] = expo[:,0]/expos\n",
    "foo[:,1] = expo[:,1]/expos\n",
    "ff=np.zeros(x1.shape[0])\n",
    "ff[foo[:,1]>0.5]=1.\n",
    "print(x1.shape)\n",
    "ee=c_mlp.predict(x1)\n",
    "ee=np.squeeze(ee)\n",
    "print(ee.shape)\n",
    "print(ff.shape)\n",
    "print(np.sum(np.logical_and(ff==0,ee==1)))\n",
    "print(np.sum(np.logical_and(ff==1,ee==0)))\n",
    "\n",
    "rexpo = np.exp(out_test_check[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot (1-d) histograms at each input and output level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,40))\n",
    "_,ax = plt.subplots(lev.size,2,sharex=True)\n",
    "for i in range(lev.size):\n",
    "    step=.05\n",
    "    bins=np.arange(-1,1+step,step)\n",
    "    n,bins,_ =ax[i,0].hist(unpack(x_train_norm,'T')[:,i],bins=bins,facecolor='yellow',alpha=0.5,normed=True)\n",
    "    n2,bins2,_=ax[i,1].hist(unpack(y_train_norm,'T')[:,i],bins=bins,facecolor='blue'  ,alpha=0.5,normed=True)\n",
    "\n",
    "\n",
    "    ax[i,0].set_xlim((-1,1))\n",
    "    ax[i,0].set_ylim(0,np.amax(n))\n",
    "    ax[i,1].set_ylim(0,np.amax(n2))\n",
    "\n",
    "\n",
    "    #ax[i,0].set_ylim([-1,1])\n",
    "    print(np.amax(n))\n",
    "    print(np.amax(n2))\n",
    "    #ax[i,1].hist(unpack(x_train_norm,'q')[:,i]*step,bins=np.arange(-1,1+step,step),facecolor='yellow',alpha=0.5,normed=True)\n",
    "    #ax[i,1].hist(unpack(y_train_norm,'q')[:,i]*step,bins=np.arange(-1,1+step,step),facecolor='blue'  ,alpha=0.5,normed=True)\n",
    "    #ax[i,1].set_xlim([-1,1])\n",
    "\n",
    "\n",
    "\n",
    "    #plt.subplot(lev.size,2,i+1+lev.size)\n",
    "    #plt.hist(y_train_norm[:,i],100,facecolor='green')\n",
    "    #ax[i,0].get_yaxis().set_visible(False)\n",
    "\n",
    "    #n, bins, patches = plt.hist(y_train_norm[:,28], 100, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate out of bag error importance for random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "oob_mlp = RandomForestRegressor(n_estimators=30)\n",
    "\n",
    "oob_mlp.fit(x2,y2)\n",
    "indmin=np.argmin(oob_mlp.feature_importances_)\n",
    "print(indmin)\n",
    "print(np.min(oob_mlp.feature_importances_))\n",
    "print(oob_mlp.score(x3,y3))\n",
    "x2 = np.delete(x2,indmin,1)\n",
    "\n",
    "plt.plot(unpack(oob_mlp.feature_importances_,'T'),lev,label='T')\n",
    "plt.plot(unpack(oob_mlp.feature_importances_,'q'),lev,label='q')\n",
    "plt.ylim((1,0))\n",
    "plt.show()\n",
    "oob_mlp2 = RandomForestRegressor(n_estimators=30)\n",
    "oob_mlp2.fit(x2[:,oob_mlp.feature_importances_>0.],cv2)\n",
    "\n",
    "#oob_mlp2.feature_importances_.shape\n",
    "np.argmin(oob_mlp.feature_importances_)#[oob_mlp.feature_importances_>0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Principal Component Analysis attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "%matplotlib inline\n",
    "reload(nnload)\n",
    "x, y, cv, Pout, lat, lev, dlev, timestep = nnload.loaddata(data_dir + 'nntest.nc', minlev,\n",
    "                                                       rainonly=rainonly) #,all_lats=False,indlat=8)\n",
    "print(x.shape)\n",
    "# pcax = PCA(n_components=10)\n",
    "# pcay = PCA(n_components=10)\n",
    "pcax=\n",
    "xpp = preprocessing.StandardScaler()\n",
    "ypp = preprocessing.StandardScaler()\n",
    "x = xpp.fit_transform(x)\n",
    "y = ypp.fit_transform(y)\n",
    "# x = pcax.fit_transform(x)\n",
    "# y = pcay.fit_transform(y)\n",
    "# Subsample data\n",
    "x1, x2, x3, y1, y2, y3 = nnload.subsample(x, y, N_samples=10000)\n",
    "\n",
    "print(pcax.explained_variance_ratio_)\n",
    "print(x2.shape)\n",
    "plt.plot(pcax.components_[0,0:15],lev,color='blue')\n",
    "plt.plot(pcax.components_[0,15:30],lev,color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
